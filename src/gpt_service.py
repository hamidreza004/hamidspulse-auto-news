import json
import os
from typing import Dict, Any, Optional
from openai import OpenAI
from src.config import Config


class GPTService:
    def __init__(self, config: Config):
        self.config = config
        base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=base_url
        )
    
    def triage_message(self, message_text: str, source_channel: str, 
                      source_url: str, current_state: str) -> Optional[Dict[str, Any]]:
        core_characteristics = "\n".join([f"- {char}" for char in self.config.get('content_style.core_characteristics', [])])
        
        system_prompt = f"""Ø´Ù…Ø§ Ø³ÛŒØ³ØªÙ… ØªØ±ÛŒØ§Ú˜ Ø®Ø¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ "Hamid's Pulse" Ù‡Ø³ØªÛŒØ¯.

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„:
{core_characteristics}

ÙˆØ¸ÛŒÙÙ‡: ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ§Ù… Ù¾Ø§ÛŒÛŒÙ† (Ù†Ù‡ ØªÙˆØ¶ÛŒØ­Ø§ØªÛŒ Ú©Ù‡ Ø¨Ø§Ù„Ø§ Ø±Ø§Ø¬Ø¹ Ø¨Ù‡ Ø¯Ø§Ù†Ø³ØªÙ‡â€ŒÙ‡Ø§Ù…ÙˆÙ† Ø¯Ø§Ø¯Ù…) Ùˆ ØªØ¹ÛŒÛŒÙ† Ø¯Ø³ØªÙ‡ Ø§Ù‡Ù…ÛŒØª Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„.

Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ:
- HIGH: Ø®Ø¨Ø± ÙÙˆØ±ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ ÙÙˆØ±Ø§Ù‹ Ù…Ù†ØªØ´Ø± Ø´ÙˆØ¯ Ùˆ ÛŒØ§ Ø®ÛŒÙ„ÛŒ Ø²ÛŒØ§Ø¯ Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ù…ÛŒØªÙˆØ§Ù†Ø¯ ØªØ§Ø«ÛŒØ±Ú¯Ø°Ø§Ø± Ø¨Ø§Ø´Ø¯ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ù†Ø²Ø¯ÛŒÚ©
- MEDIUM: Ø®Ø¨Ø± Ù…Ù‡Ù… Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø®Ù„Ø§ØµÙ‡ Ø³Ø§Ø¹ØªÛŒ Ù…ÙÛŒØ¯ Ø§Ø³Øª
- LOW:
 Ø®Ø¨Ø± Ú©Ù…â€ŒØ§Ù‡Ù…ÛŒØª Ú©Ù‡ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø¯Ø± Ø®Ù„Ø§ØµÙ‡ Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…ÛŒâ€ŒØ¢ÛŒØ¯ØŒ Ø®Ø¨Ø±Ù‡Ø§ÛŒ Ù†ØµÙÙ‡ ÛŒØ§ ØªÚ© Ø¬Ù…Ù„Ù‡ Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø±Ø²Ø´ Ø®Ø¨Ø±ÛŒ Ù†Ø¯Ø§Ø±Ù†Ø¯ Ùˆ ØµØ§Ø­Ø¨ Ú©Ø§Ù†Ø§Ù„ ØµØ±ÙØ§ Ø­Ø±Ù Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø²Ø¯Ù‡ ÛŒØ§ ØªØ¨Ù„ÛŒØº Ú¯Ø°Ø§Ø´ØªÙ‡ Ø¯Ø± Ø§ÛŒÙ† Ø¯Ø³ØªÙ‡ Ù‡Ø³ØªÙ†Ø¯.

Ø®Ø±ÙˆØ¬ÛŒ: ÙÙ‚Ø· JSON (Ø¨Ø¯ÙˆÙ† markdownØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡):
{{
  "bucket": "high" | "medium" | "low",
  "novelty_delta": "ÛŒÚ© Ø¬Ù…Ù„Ù‡ ÙØ§Ø±Ø³ÛŒ: Ú†Ù‡ Ú†ÛŒØ²ÛŒ Ø¯Ø± Ù¾ÛŒØ§Ù… Ù…Ø±Ø¨ÙˆØ·Ù‡ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ù‡ Ù†Ø³Ø¨Øª Ø¯Ø§Ù†Ø³ØªÙ‡ Ù…Ø§ Ø¬Ø¯ÛŒØ¯ Ø§Ø³ØªØŸ Ø§Ú¯Ø± Ù¾ÛŒØ§Ù… Ø¨ÛŒ Ø§Ø±Ø²Ø´ Ù‡Ø³Øª Ù‡Ù… Ø¨Ú¯Ùˆ",
  "reason": "Ø¯Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ ÙØ§Ø±Ø³ÛŒ",
  "key_points": ["Ù†Ú©ØªÙ‡ 1", "Ù†Ú©ØªÙ‡ 2"]
}}"""

        user_prompt = f"""ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø®Ø¨Ø±ÛŒ (Situation Brief):
{current_state}

---

Ú©Ø§Ù†Ø§Ù„ Ù…Ù†Ø¨Ø¹ Ø§ÛŒÙ† Ù¾ÛŒØ§Ù…: {source_channel}
Ù„ÛŒÙ†Ú© Ø§ÛŒÙ† Ù¾ÛŒØ§Ù…: {source_url}

Ø§ÛŒÙ† Ø§ÙˆÙ† Ù¾ÛŒØ§Ù…ÛŒ Ù‡Ø³Øª Ú©Ù‡ Ù‚Ø±Ø§Ø±Ù‡ ØªÙˆ Ù‚Ø¶Ø§ÙˆØª Ú©Ù†ÛŒØŒ Ù¾ÛŒØ§Ù… Ù¾Ø§ÛŒÛŒÙ† ØªÙ†Ù‡Ø§ Ú†ÛŒØ²ÛŒÙ‡ Ú©Ù‡ Ù‚Ø±Ø§Ø±Ù‡ Ù†Ø¸Ø± Ø®ÙˆØ¯Øª Ø±Ùˆ Ø¯Ø± Ù…ÙˆØ±Ø¯Ø´ Ø¨Ú¯ÛŒØŒ Ø§Ú¯Ù‡ Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡Ù‡ ÛŒØ§ Ù†Ø§Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø¨Ø§ÛŒØ¯ Ù‡Ù…ÛŒÙ† Ø±Ùˆ Ø°Ú©Ø± Ú©Ù†ÛŒ.
Ù¾ÛŒØ§Ù… Ù…Ø±Ø¨ÙˆØ·Ù‡:

{message_text}

Ù…ÛŒØ®ÙˆØ§ÛŒ ÛŒÙ‡ Ø¨Ø§Ø± Ø¯ÛŒÚ¯Ù‡ ØªÚ©Ø±Ø§Ø± Ù…ÛŒÚ©Ù†Ù… Ù¾ÛŒØ§Ù… Ø±Ùˆ 

---

{message_text}

---

Ø§ÛŒÙ† Ù¾ÛŒØ§Ù… Ø¨Ø§Ù„Ø§ Ø±Ø§ ÙÙ‚Ø· ØªØ±ÛŒØ§Ú˜ Ú©Ù† Ùˆ JSON Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø¯Ù‡."""

        try:
            import logging
            logger = logging.getLogger(__name__)
            logger.info(f"Calling GPT triage with model: {self.config.triage_model}")
            
            response = self.client.chat.completions.create(
                model=self.config.triage_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=1.0,
                max_tokens=self.config.get('gpt_models.max_tokens_triage', 50000)
            )
            
            logger.info(f"GPT response received. Choices count: {len(response.choices)}")
            if response.choices:
                logger.info(f"First choice finish_reason: {response.choices[0].finish_reason}")
            
            content = response.choices[0].message.content
            logger.info(f"Response content length: {len(content) if content else 0}")
            logger.info(f"Response content preview: '{content[:100] if content else 'NONE'}...'")
            if not content or content.strip() == "":
                logger.error(f"GPT returned empty response. Model: {self.config.triage_model}")
                logger.error(f"Response object: {response}")
                logger.error(f"Full API response for debugging: {response.model_dump_json() if hasattr(response, 'model_dump_json') else str(response)}")
                return None
            
            # Extract JSON from markdown code blocks if present
            content = content.strip()
            if content.startswith("```"):
                lines = content.split("\n")
                content = "\n".join(lines[1:-1]) if len(lines) > 2 else content
                content = content.replace("```json", "").replace("```", "").strip()
            
            try:
                result = json.loads(content)
            except json.JSONDecodeError as je:
                import logging
                logger = logging.getLogger(__name__)
                logger.error(f"JSON decode error. Response content: '{content[:500]}...'")
                logger.error(f"Full response for debugging: {content}")
                raise
            
            bucket = result.get('bucket', 'low')
            logger.info(f"Triage: bucket={bucket}, reason={result.get('reason', '')[:50]}")
            
            return result
            
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"Error in GPT triage: {e}", exc_info=True)
            return None
    
    def generate_high_post(self, message_text: str, source_channel: str,
                          source_url: str, triage_result: dict, current_state: str) -> Optional[str]:
        core_characteristics = "\n".join([f"- {char}" for char in self.config.get('content_style.core_characteristics', [])])
        emoji_rules = self.config.get('content_style.emoji_logic', {})
        high_emoji_count = emoji_rules.get('high_news_emoji_count', 3)
        emoji_guidelines = emoji_rules.get('guidelines', '')
        
        system_prompt = f"""Ø´Ù…Ø§ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù†Ø§Ù„ "Hamid's Pulse" Ù‡Ø³ØªÛŒØ¯.

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„:
{core_characteristics}

Ù‚Ø§Ù„Ø¨ Ø¯Ù‚ÛŒÙ‚ Ù¾Ø³Øª HIGH:
{high_emoji_count} Ø§ÛŒÙ…ÙˆØ¬ÛŒ **Ø¹Ù†ÙˆØ§Ù† Ø®Ø¨Ø± (bold)**

[{source_channel} | Ù„ÛŒÙ†Ú©]({source_url})

Ù…ØªÙ† ØªÙˆØ¶ÛŒØ­ Ø¯Ø± ÛŒÚ© ÛŒØ§ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡

@hamidspulse ğŸ”­

Ù…Ù‡Ù…: Ø­ØªÙ…Ø§Ù‹ URL ÙˆØ§Ù‚Ø¹ÛŒ Ø±Ø§ Ø¯Ø± Ù¾Ø±Ø§Ù†ØªØ² Ø¨Ú¯Ø°Ø§Ø±ØŒ Ù†Ù‡ Ú©Ù„Ù…Ù‡ "URL" ÛŒØ§ "Ù„ÛŒÙ†Ú©"

Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ:
{emoji_guidelines}

Ù†Ú©Ø§Øª:
- Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ù‚Ø¨Ù„ Ø§Ø² Ø¹Ù†ÙˆØ§Ù† Ø¯Ø± Ù‡Ù…Ø§Ù† Ø®Ø·
- Ø¹Ù†ÙˆØ§Ù† boldØŒ 3-6 Ú©Ù„Ù…Ù‡ØŒ Ø¨Ø¯ÙˆÙ† Ø¨Ø±Ø§Ú©Øª
- Ù„ÛŒÙ†Ú© Ù…Ù†Ø¨Ø¹ Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ Ø¯Ø± Ø®Ø· Ø¨Ø¹Ø¯ÛŒ
- Ù…ØªÙ† ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø¹Ø¯ Ø§Ø² Ù„ÛŒÙ†Ú©
- Ù…Ù†Ø¨Ø¹ Ø¨Ø§ ÙØ±Ù…Øª markdown Ø¯Ù‚ÛŒÙ‚: [{source_channel} | Ù„ÛŒÙ†Ú©]({source_url})
- URL Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù‡Ù…Ø§Ù† Ù„ÛŒÙ†Ú©ÛŒ Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø¯Ø± Ø¨Ø®Ø´ "Ù„ÛŒÙ†Ú©" Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡
- ÙÙ‚Ø· ÛŒÚ© Ø¨Ø§Ø± @hamidspulse ğŸ”­ Ø¯Ø± Ø§Ù†ØªÙ‡Ø§"""

        key_points = "\n".join([f"- {p}" for p in triage_result.get('key_points', [])])
        user_prompt = f"""ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ:
{current_state[:500]}

---

Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯ HIGH:
Ù…Ù†Ø¨Ø¹: {source_channel}
Ù„ÛŒÙ†Ú©: {source_url}

Ù…ØªÙ†:
{message_text}

Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:
{key_points}

Ø¯Ù„ÛŒÙ„: {triage_result.get('reason', '')}
Ù†ÙˆØ¢ÙˆØ±ÛŒ: {triage_result.get('novelty_delta', '')}

ÛŒÚ© Ù¾Ø³Øª Ø¬Ø°Ø§Ø¨ Ø¨Ù†ÙˆÛŒØ³ (Ù‚Ø§Ù„Ø¨ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§Ù„Ø§)."""

        try:
            response = self.client.chat.completions.create(
                model=self.config.content_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=1.0,
                max_tokens=self.config.get('gpt_models.max_tokens_content', 50000)
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating HIGH post: {e}")
            return None
    
    def generate_hourly_digest(self, medium_items: list, current_state: str,
                              start_time: str, end_time: str) -> Optional[str]:
        core_characteristics = "\n".join([f"- {char}" for char in self.config.get('content_style.core_characteristics', [])])
        min_bullets = self.config.get('content_style.writing_guidelines.min_bullets_per_digest', 3)
        max_bullets = self.config.get('content_style.writing_guidelines.max_bullets_per_digest', 8)
        
        # Format time as hours only with bold (e.g., "**23:00-00:00**")
        start_hour = start_time.strftime('%H:%M') if hasattr(start_time, 'strftime') else str(start_time)
        end_hour = end_time.strftime('%H:%M') if hasattr(end_time, 'strftime') else str(end_time)
        title = f"ğŸ• Ø¨Ø±Ø®ÛŒ Ø§Ø®Ø¨Ø§Ø± **{start_hour}â€“{end_hour}**"
        
        system_prompt = f"""Ø´Ù…Ø§ Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ø§Ù†Ø§Ù„ "Hamid's Pulse" Ù‡Ø³ØªÛŒØ¯.

ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„:
{core_characteristics}

Ù‚Ø§Ù„Ø¨ Ø¯Ù‚ÛŒÙ‚:
{title}

[Ù‡Ø± Ø®Ø¨Ø± Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ]
[Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹ | Ù„ÛŒÙ†Ú©](URL Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù„ÛŒØ³Øª Ø²ÛŒØ±)

[Ø®Ø¨Ø± Ø¨Ø¹Ø¯ÛŒ Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ]
[Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹ | Ù„ÛŒÙ†Ú©](URL Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù„ÛŒØ³Øª Ø²ÛŒØ±)

... ({min_bullets}-{max_bullets} Ø®Ø¨Ø±)

@hamidspulse ğŸ”­

Ù†Ú©Ø§Øª Ù…Ù‡Ù…:
- Ù‡Ø± Ø®Ø¨Ø± = ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒ
- Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ± Ù‡Ø± Ø®Ø¨Ø±ØŒ Ù…Ù†Ø¨Ø¹ Ø¢Ù† Ø¯Ø± Ø®Ø· Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
- Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø§ ÙØ±Ù…Øª markdown: [Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹ | Ù„ÛŒÙ†Ú©](URL)
- Ø­ØªÙ…Ø§Ù‹ URL Ø¯Ù‚ÛŒÙ‚ Ø§Ø² Ù„ÛŒØ³Øª Ø§Ø®Ø¨Ø§Ø± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† - Ù‡Ø± Ø®Ø¨Ø± URL Ø®ÙˆØ¯Ø´ Ø±Ø§ Ø¯Ø§Ø±Ø¯
- Ø§Ú¯Ø± Ø§Ø² Ú†Ù†Ø¯ Ù…Ù†Ø¨Ø¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŒ Ù‡Ù…Ù‡ URLÙ‡Ø§ Ø±Ø§ Ø¯Ø±Ø³Øª Ø¨Ú¯Ø°Ø§Ø±
- ÙÙ‚Ø· Ø®Ø¨Ø± Ø®Ø§Ù…ØŒ Ù†Ù‡ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ Ø­Ø¯Ø³
- Ø¨Ø¯ÙˆÙ† Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„ "Ø§ÛŒÙ† ÛŒØ¹Ù†ÛŒ"ØŒ "Ø§Ø­ØªÙ…Ø§Ù„"ØŒ "Ù…Ù…Ú©Ù† Ø§Ø³Øª"
- {min_bullets}-{max_bullets} Ø®Ø¨Ø± Ú©Ù„Ø§Ù‹"""

        items_text = ""
        for idx, item in enumerate(medium_items, 1):
            items_text += f"\n{idx}. Ù…Ù†Ø¨Ø¹: {item['source_channel']}\n"
            items_text += f"   Ù„ÛŒÙ†Ú©: {item['source_url']}\n"
            items_text += f"   Ù…ØªÙ†: {item['message_text'][:300]}...\n"
            items_text += f"   Ù†Ú©Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: {', '.join(item['triage_json'].get('key_points', []))}\n"
        
        user_prompt = f"""ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ:
{current_state}

---

Ø§Ø®Ø¨Ø§Ø± Ø¨Ø§ Ø§Ù‡Ù…ÛŒØª Ù…ØªÙˆØ³Ø· Ø¯Ø± Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ ({len(medium_items)} Ù…ÙˆØ±Ø¯):
{items_text}

---

ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ Ø³Ø§Ø¹ØªÛŒ Ø¨Ù†ÙˆÛŒØ³ - Ù‡Ø± bullet ÙÙ‚Ø· ÛŒÚ© Ø®Ø¨Ø±ØŒ Ø¨Ø¯ÙˆÙ† ØªØ­Ù„ÛŒÙ„ ÛŒØ§ Ø­Ø¯Ø³."""

        try:
            response = self.client.chat.completions.create(
                model=self.config.content_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=1.0,
                max_tokens=self.config.get('gpt_models.max_tokens_content', 50000)
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"Error generating 3-hour digest: {e}")
            return None
    
    def update_situation_brief(self, current_brief: str, new_event: str, 
                              event_type: str = "high_post") -> str:
        system_prompt = """Ø´Ù…Ø§ Ù…Ø¯ÛŒØ± Ø­Ø§ÙØ¸Ù‡ Ø®Ø¨Ø±ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡â€ŒØªØ§Ù† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ "Situation Brief" Ø§Ø³Øª.

Situation Brief = Ø®Ù„Ø§ØµÙ‡ ÙØ´Ø±Ø¯Ù‡ ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø®Ø¨Ø±ÛŒ (Ø­Ø¯Ø§Ú©Ø«Ø± 1200 Ú©Ø§Ø±Ø§Ú©ØªØ±)

ÙˆØ¸ÛŒÙÙ‡: 
1. Brief ÙØ¹Ù„ÛŒ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†
2. Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ú¯ÛŒØ±
3. Brief Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø² Ú©Ù‡:
   - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‚Ø¯ÛŒÙ…ÛŒ Ú©Ù…â€ŒØ§Ù‡Ù…ÛŒØª Ø±Ø§ Ø­Ø°Ù Ú©Ù†Ø¯
   - Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†Ø¯
   - ÙØ´Ø±Ø¯Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯
   - Ø²Ù…ÛŒÙ†Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±ÛŒØ§Ú˜ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø¯Ù‡Ø¯

ÙÙ‚Ø· Ù…ØªÙ† Brief Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÛŒ."""

        user_prompt = f"""Brief ÙØ¹Ù„ÛŒ:
{current_brief}

---

Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¬Ø¯ÛŒØ¯ ({event_type}):
{new_event}

---

Brief Ø¬Ø¯ÛŒØ¯ (Ø­Ø¯Ø§Ú©Ø«Ø± 1200 Ú©Ø§Ø±Ø§Ú©ØªØ±):"""

        try:
            response = self.client.chat.completions.create(
                model=self.config.triage_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=1.0,
                max_tokens=50000
            )
            
            new_brief = response.choices[0].message.content.strip()
            return new_brief[:1200]
            
        except Exception as e:
            print(f"Error updating situation brief: {e}")
            return current_brief
